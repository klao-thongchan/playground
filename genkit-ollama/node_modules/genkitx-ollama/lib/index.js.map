{"version":3,"sources":["../src/index.ts"],"sourcesContent":["/**\n * Copyright 2024 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport {\n  CandidateData,\n  defineModel,\n  GenerateRequest,\n  GenerateResponseData,\n  GenerationCommonConfigSchema,\n  getBasicUsageStats,\n  MessageData,\n} from '@genkit-ai/ai/model';\nimport { genkitPlugin, Plugin } from '@genkit-ai/core';\nimport { logger } from '@genkit-ai/core/logging';\n\ntype ApiType = 'chat' | 'generate';\n\ntype RequestHeaders =\n  | Record<string, string>\n  | ((\n      params: { serverAddress: string; model: ModelDefinition },\n      request: GenerateRequest\n    ) => Promise<Record<string, string> | void>);\n\ntype ModelDefinition = { name: string; type?: ApiType };\n\nexport interface OllamaPluginParams {\n  models: ModelDefinition[];\n  /**\n   *  ollama server address.\n   */\n  serverAddress: string;\n\n  requestHeaders?: RequestHeaders;\n}\n\nexport const ollama: Plugin<[OllamaPluginParams]> = genkitPlugin(\n  'ollama',\n  async (params: OllamaPluginParams) => {\n    const serverAddress = params?.serverAddress;\n    return {\n      models: params.models.map((model) =>\n        ollamaModel(model, serverAddress, params.requestHeaders)\n      ),\n    };\n  }\n);\n\nfunction ollamaModel(\n  model: ModelDefinition,\n  serverAddress: string,\n  requestHeaders?: RequestHeaders\n) {\n  return defineModel(\n    {\n      name: `ollama/${model.name}`,\n      label: `Ollama - ${model.name}`,\n      configSchema: GenerationCommonConfigSchema,\n      supports: {\n        multiturn: !model.type || model.type === 'chat',\n      },\n    },\n    async (input, streamingCallback) => {\n      const options: Record<string, any> = {};\n      if (input.config?.hasOwnProperty('temperature')) {\n        options.temperature = input.config?.temperature;\n      }\n      if (input.config?.hasOwnProperty('topP')) {\n        options.top_p = input.config?.topP;\n      }\n      if (input.config?.hasOwnProperty('topK')) {\n        options.top_k = input.config?.topK;\n      }\n      if (input.config?.hasOwnProperty('stopSequences')) {\n        options.stop = input.config?.stopSequences?.join('');\n      }\n      if (input.config?.hasOwnProperty('maxOutputTokens')) {\n        options.num_predict = input.config?.maxOutputTokens;\n      }\n      const type = model.type ?? 'chat';\n      const request = toOllamaRequest(\n        model.name,\n        input,\n        options,\n        type,\n        !!streamingCallback\n      );\n      logger.debug(request, `ollama request (${type})`);\n\n      const extraHeaders = requestHeaders\n        ? typeof requestHeaders === 'function'\n          ? await requestHeaders(\n              {\n                serverAddress,\n                model,\n              },\n              input\n            )\n          : requestHeaders\n        : {};\n\n      let res;\n      try {\n        res = await fetch(\n          serverAddress + (type === 'chat' ? '/api/chat' : '/api/generate'),\n          {\n            method: 'POST',\n            body: JSON.stringify(request),\n            headers: {\n              'Content-Type': 'application/json',\n              ...extraHeaders,\n            },\n          }\n        );\n      } catch (e) {\n        const cause = (e as any).cause;\n        if (cause) {\n          if (\n            cause instanceof Error &&\n            cause.message?.includes('ECONNREFUSED')\n          ) {\n            cause.message += '. Make sure ollama server is running.';\n          }\n          throw cause;\n        }\n        throw e;\n      }\n      if (!res.body) {\n        throw new Error('Response has no body');\n      }\n\n      const responseCandidates: CandidateData[] = [];\n\n      if (streamingCallback) {\n        const reader = res.body.getReader();\n        const textDecoder = new TextDecoder();\n        let textResponse = '';\n        for await (const chunk of readChunks(reader)) {\n          const chunkText = textDecoder.decode(chunk);\n          const json = JSON.parse(chunkText);\n          const message = parseMessage(json, type);\n          streamingCallback({\n            index: 0,\n            content: message.content,\n          });\n          textResponse += message.content[0].text;\n        }\n        responseCandidates.push({\n          index: 0,\n          finishReason: 'stop',\n          message: {\n            role: 'model',\n            content: [\n              {\n                text: textResponse,\n              },\n            ],\n          },\n        } as CandidateData);\n      } else {\n        const txtBody = await res.text();\n        const json = JSON.parse(txtBody);\n        logger.debug(txtBody, 'ollama raw response');\n\n        responseCandidates.push({\n          index: 0,\n          finishReason: 'stop',\n          message: parseMessage(json, type),\n        } as CandidateData);\n      }\n\n      return {\n        candidates: responseCandidates,\n        usage: getBasicUsageStats(input.messages, responseCandidates),\n      } as GenerateResponseData;\n    }\n  );\n}\n\nfunction parseMessage(response: any, type: ApiType): MessageData {\n  if (response.error) {\n    throw new Error(response.error);\n  }\n  if (type === 'chat') {\n    return {\n      role: toGenkitRole(response.message.role),\n      content: [\n        {\n          text: response.message.content,\n        },\n      ],\n    };\n  } else {\n    return {\n      role: 'model',\n      content: [\n        {\n          text: response.response,\n        },\n      ],\n    };\n  }\n}\n\nfunction toOllamaRequest(\n  name: string,\n  input: GenerateRequest,\n  options: Record<string, any>,\n  type: ApiType,\n  stream: boolean\n) {\n  const request = {\n    model: name,\n    options,\n    stream,\n  } as any;\n  if (type === 'chat') {\n    const messages: Message[] = [];\n    input.messages.forEach((m) => {\n      let messageText = '';\n      const images: string[] = [];\n      m.content.forEach((c) => {\n        if (c.text) {\n          messageText += c.text;\n        }\n        if (c.media) {\n          images.push(c.media.url);\n        }\n      });\n      messages.push({\n        role: toOllamaRole(m.role),\n        content: messageText,\n        images: images.length > 0 ? images : undefined,\n      });\n    });\n    request.messages = messages;\n  } else {\n    request.prompt = getPrompt(input);\n  }\n  return request;\n}\n\nfunction toOllamaRole(role) {\n  if (role === 'model') {\n    return 'assistant';\n  }\n  return role; // everything else seems to match\n}\n\nfunction toGenkitRole(role) {\n  if (role === 'assistant') {\n    return 'model';\n  }\n  return role; // everything else seems to match\n}\n\nfunction readChunks(reader) {\n  return {\n    async *[Symbol.asyncIterator]() {\n      let readResult = await reader.read();\n      while (!readResult.done) {\n        yield readResult.value;\n        readResult = await reader.read();\n      }\n    },\n  };\n}\n\nfunction getPrompt(input: GenerateRequest) {\n  return input.messages.map((m) => m.content.map((c) => c.text).join()).join();\n}\n\ninterface Message {\n  role: string;\n  content: string;\n  images?: string[];\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAgBA,mBAQO;AACP,kBAAqC;AACrC,qBAAuB;AAuBhB,MAAM,aAAuC;AAAA,EAClD;AAAA,EACA,CAAO,WAA+B;AACpC,UAAM,gBAAgB,iCAAQ;AAC9B,WAAO;AAAA,MACL,QAAQ,OAAO,OAAO;AAAA,QAAI,CAAC,UACzB,YAAY,OAAO,eAAe,OAAO,cAAc;AAAA,MACzD;AAAA,IACF;AAAA,EACF;AACF;AAEA,SAAS,YACP,OACA,eACA,gBACA;AACA,aAAO;AAAA,IACL;AAAA,MACE,MAAM,UAAU,MAAM,IAAI;AAAA,MAC1B,OAAO,YAAY,MAAM,IAAI;AAAA,MAC7B,cAAc;AAAA,MACd,UAAU;AAAA,QACR,WAAW,CAAC,MAAM,QAAQ,MAAM,SAAS;AAAA,MAC3C;AAAA,IACF;AAAA,IACA,CAAO,OAAO,sBAAsB;AA3ExC;AA4EM,YAAM,UAA+B,CAAC;AACtC,WAAI,WAAM,WAAN,mBAAc,eAAe,gBAAgB;AAC/C,gBAAQ,eAAc,WAAM,WAAN,mBAAc;AAAA,MACtC;AACA,WAAI,WAAM,WAAN,mBAAc,eAAe,SAAS;AACxC,gBAAQ,SAAQ,WAAM,WAAN,mBAAc;AAAA,MAChC;AACA,WAAI,WAAM,WAAN,mBAAc,eAAe,SAAS;AACxC,gBAAQ,SAAQ,WAAM,WAAN,mBAAc;AAAA,MAChC;AACA,WAAI,WAAM,WAAN,mBAAc,eAAe,kBAAkB;AACjD,gBAAQ,QAAO,iBAAM,WAAN,mBAAc,kBAAd,mBAA6B,KAAK;AAAA,MACnD;AACA,WAAI,WAAM,WAAN,mBAAc,eAAe,oBAAoB;AACnD,gBAAQ,eAAc,WAAM,WAAN,mBAAc;AAAA,MACtC;AACA,YAAM,QAAO,WAAM,SAAN,YAAc;AAC3B,YAAM,UAAU;AAAA,QACd,MAAM;AAAA,QACN;AAAA,QACA;AAAA,QACA;AAAA,QACA,CAAC,CAAC;AAAA,MACJ;AACA,4BAAO,MAAM,SAAS,mBAAmB,IAAI,GAAG;AAEhD,YAAM,eAAe,iBACjB,OAAO,mBAAmB,aACxB,MAAM;AAAA,QACJ;AAAA,UACE;AAAA,UACA;AAAA,QACF;AAAA,QACA;AAAA,MACF,IACA,iBACF,CAAC;AAEL,UAAI;AACJ,UAAI;AACF,cAAM,MAAM;AAAA,UACV,iBAAiB,SAAS,SAAS,cAAc;AAAA,UACjD;AAAA,YACE,QAAQ;AAAA,YACR,MAAM,KAAK,UAAU,OAAO;AAAA,YAC5B,SAAS;AAAA,cACP,gBAAgB;AAAA,eACb;AAAA,UAEP;AAAA,QACF;AAAA,MACF,SAAS,GAAG;AACV,cAAM,QAAS,EAAU;AACzB,YAAI,OAAO;AACT,cACE,iBAAiB,WACjB,WAAM,YAAN,mBAAe,SAAS,kBACxB;AACA,kBAAM,WAAW;AAAA,UACnB;AACA,gBAAM;AAAA,QACR;AACA,cAAM;AAAA,MACR;AACA,UAAI,CAAC,IAAI,MAAM;AACb,cAAM,IAAI,MAAM,sBAAsB;AAAA,MACxC;AAEA,YAAM,qBAAsC,CAAC;AAE7C,UAAI,mBAAmB;AACrB,cAAM,SAAS,IAAI,KAAK,UAAU;AAClC,cAAM,cAAc,IAAI,YAAY;AACpC,YAAI,eAAe;AACnB;AAAA,qCAA0B,WAAW,MAAM,IAA3C,0EAA8C;AAAnC,kBAAM,QAAjB;AACE,kBAAM,YAAY,YAAY,OAAO,KAAK;AAC1C,kBAAM,OAAO,KAAK,MAAM,SAAS;AACjC,kBAAM,UAAU,aAAa,MAAM,IAAI;AACvC,8BAAkB;AAAA,cAChB,OAAO;AAAA,cACP,SAAS,QAAQ;AAAA,YACnB,CAAC;AACD,4BAAgB,QAAQ,QAAQ,CAAC,EAAE;AAAA,UACrC;AAAA,iBATA,MAtJR;AAsJQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAUA,2BAAmB,KAAK;AAAA,UACtB,OAAO;AAAA,UACP,cAAc;AAAA,UACd,SAAS;AAAA,YACP,MAAM;AAAA,YACN,SAAS;AAAA,cACP;AAAA,gBACE,MAAM;AAAA,cACR;AAAA,YACF;AAAA,UACF;AAAA,QACF,CAAkB;AAAA,MACpB,OAAO;AACL,cAAM,UAAU,MAAM,IAAI,KAAK;AAC/B,cAAM,OAAO,KAAK,MAAM,OAAO;AAC/B,8BAAO,MAAM,SAAS,qBAAqB;AAE3C,2BAAmB,KAAK;AAAA,UACtB,OAAO;AAAA,UACP,cAAc;AAAA,UACd,SAAS,aAAa,MAAM,IAAI;AAAA,QAClC,CAAkB;AAAA,MACpB;AAEA,aAAO;AAAA,QACL,YAAY;AAAA,QACZ,WAAO,iCAAmB,MAAM,UAAU,kBAAkB;AAAA,MAC9D;AAAA,IACF;AAAA,EACF;AACF;AAEA,SAAS,aAAa,UAAe,MAA4B;AAC/D,MAAI,SAAS,OAAO;AAClB,UAAM,IAAI,MAAM,SAAS,KAAK;AAAA,EAChC;AACA,MAAI,SAAS,QAAQ;AACnB,WAAO;AAAA,MACL,MAAM,aAAa,SAAS,QAAQ,IAAI;AAAA,MACxC,SAAS;AAAA,QACP;AAAA,UACE,MAAM,SAAS,QAAQ;AAAA,QACzB;AAAA,MACF;AAAA,IACF;AAAA,EACF,OAAO;AACL,WAAO;AAAA,MACL,MAAM;AAAA,MACN,SAAS;AAAA,QACP;AAAA,UACE,MAAM,SAAS;AAAA,QACjB;AAAA,MACF;AAAA,IACF;AAAA,EACF;AACF;AAEA,SAAS,gBACP,MACA,OACA,SACA,MACA,QACA;AACA,QAAM,UAAU;AAAA,IACd,OAAO;AAAA,IACP;AAAA,IACA;AAAA,EACF;AACA,MAAI,SAAS,QAAQ;AACnB,UAAM,WAAsB,CAAC;AAC7B,UAAM,SAAS,QAAQ,CAAC,MAAM;AAC5B,UAAI,cAAc;AAClB,YAAM,SAAmB,CAAC;AAC1B,QAAE,QAAQ,QAAQ,CAAC,MAAM;AACvB,YAAI,EAAE,MAAM;AACV,yBAAe,EAAE;AAAA,QACnB;AACA,YAAI,EAAE,OAAO;AACX,iBAAO,KAAK,EAAE,MAAM,GAAG;AAAA,QACzB;AAAA,MACF,CAAC;AACD,eAAS,KAAK;AAAA,QACZ,MAAM,aAAa,EAAE,IAAI;AAAA,QACzB,SAAS;AAAA,QACT,QAAQ,OAAO,SAAS,IAAI,SAAS;AAAA,MACvC,CAAC;AAAA,IACH,CAAC;AACD,YAAQ,WAAW;AAAA,EACrB,OAAO;AACL,YAAQ,SAAS,UAAU,KAAK;AAAA,EAClC;AACA,SAAO;AACT;AAEA,SAAS,aAAa,MAAM;AAC1B,MAAI,SAAS,SAAS;AACpB,WAAO;AAAA,EACT;AACA,SAAO;AACT;AAEA,SAAS,aAAa,MAAM;AAC1B,MAAI,SAAS,aAAa;AACxB,WAAO;AAAA,EACT;AACA,SAAO;AACT;AAEA,SAAS,WAAW,QAAQ;AAC1B,SAAO;AAAA,IACL,CAAQ,OAAO,aAAa,IAAI;AAAA;AAC9B,YAAI,aAAa,kBAAM,OAAO,KAAK;AACnC,eAAO,CAAC,WAAW,MAAM;AACvB,gBAAM,WAAW;AACjB,uBAAa,kBAAM,OAAO,KAAK;AAAA,QACjC;AAAA,MACF;AAAA;AAAA,EACF;AACF;AAEA,SAAS,UAAU,OAAwB;AACzC,SAAO,MAAM,SAAS,IAAI,CAAC,MAAM,EAAE,QAAQ,IAAI,CAAC,MAAM,EAAE,IAAI,EAAE,KAAK,CAAC,EAAE,KAAK;AAC7E;","names":[]}