{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import bs4 as bs\n",
    "import os\n",
    "import requests\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic web scriping\n",
    "\n",
    "link = \"\"\n",
    "\n",
    "def parse_data(link):\n",
    "    response = requests.get(link)\n",
    "    soup = bs(response.content)\n",
    "    selection = soup.findAll('a', class_='current reference interval')[0].text.replace('\\n', '')\n",
    "    child_section = soup.find('li', class_='toctree_li current active has-children')\n",
    "    function = [i.text.replace('\\n', '') for i in child_section.findAll('a') class_='reference internal']\n",
    "\n",
    "    data = {\n",
    "        'section': [section]*len(children),\n",
    "        'functions': functions\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web scraping - data science source code\n",
    "\n",
    "def download_nb_from_id(_id, name, folder_dir):\n",
    "    url = f\"http://www.kaggle.com/kernels/scriptcontent/{_id}/download\"\n",
    "    file = f'{_id}_{name}.ipynb'\n",
    "    local_filename = os.path.join(folder_dir, file)\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    return local_filename"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
